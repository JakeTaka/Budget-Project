{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "35786873-b9ce-45e9-abd2-ebfa22c7cbf6",
   "metadata": {},
   "source": [
    "## Monthly Budget Notebook\n",
    "#### Hi, thanks for taking a look at my budgeting notebook. This process used to be a lot simpler when I used a service called Empower and their \"Personal Dashboard\" for transaction aggregation. Then I started to notice some discrepancies and began to trust them less. After that, for some reason, their connectivity to Venmo went down the drain and as someone who uses Venmo a not insubstantial amount, it was leaving me with an incomplete picture of my monthly finances. I submitted support tickets but to no avail. \n",
    "\n",
    "#### So I figured this would be a useful project and at least then if I noticed things going wrong it'd be on _me_ and I'd be able to fix them _myself_.\n",
    "\n",
    "##### _NB: If you want to use this for your own budgeting purposes, feel free!_\n",
    "\n",
    "##### _Obvioulsy be careful and do so **at your own risk**. This is only set up right now for my own financial institutions that I use and has specific categorizations that I find helpful. The basic set-up for this notebook to work well is to have the notebook sitting in a directory (I have a structure that looks like this_\n",
    "##### _`~/home/jake/Budget/2025/2025-09`_\n",
    "##### _) and then have a sub directory called `Statements` which itself has a directory for each financial instituion that you have gathered statements from(`AmEx`,`Chase`,etc.)._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3793ad6-f1d1-4eb2-b1bf-5cdee13a7d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2393eac5-4874-47b5-bbf4-19c4cbc95398",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Aggregating a given month's statements into DataFrames\n",
    "amex_paths = glob.glob(\"Statements/AmEx/*.csv\")\n",
    "amex_df = pd.concat([pd.read_csv(file) for file in amex_paths])\n",
    "\n",
    "\n",
    "chase_path = glob.glob(\"Statements/Chase/*.CSV\")\n",
    "chase_df = pd.read_csv(chase_path[0])\n",
    "\n",
    "venmo_path = glob.glob(\"Statements/Venmo/*.csv\")\n",
    "venmo_df = pd.read_csv(venmo_path[0],header=2)\n",
    "\n",
    "wells_fargo_path = glob.glob(\"Statements/Wells Fargo/*.csv\")\n",
    "wells_fargo_df = pd.read_csv(wells_fargo_path[0], header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11c4549e-501b-46a9-9c20-fe32d79cbd6b",
   "metadata": {},
   "source": [
    "### These next few cells can be safely turned off after actual use. I'm preserving them here to help show the process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b18b7b0-33b5-4802-9a71-696b9e7b127c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting a quick look at the df columns pt.1\n",
    "print(f\"AmEx Columns {amex_df.columns}\")\n",
    "print(f\"Chase Columns{chase_df.columns}\")\n",
    "print(f\"Venmo Columns{venmo_df.columns}\")\n",
    "print(f\"Wells Fargo Columns{wells_fargo_df.columns}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f16e6fec-0c59-4e0b-8191-8cb64e685b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting a quick look at the df columns pt.2\n",
    "print(amex_df.head())\n",
    "print(chase_df.head())\n",
    "print(venmo_df.head())\n",
    "print(wells_fargo_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b337bd6-b202-4864-9a20-4b1dc1423fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reordering the columns and dropping the ones I don't want before concatinating all of the dfs together\n",
    "\n",
    "#AmEx\n",
    "amex_df = amex_df[(amex_df['Amount'] >= 0) | \n",
    "    amex_df['Description'].str.contains(\"credit\", case=False)]\n",
    "amex_df['Amount'] = amex_df['Amount'].apply(\n",
    "    lambda x: f\"+{abs(x):.2f}\" if x <= 0 else f\"{-1*x:.2f}\")\n",
    "\n",
    "#Chase\n",
    "chase_df = chase_df.iloc[:,[0,1,2]]\n",
    "chase_df = chase_df.rename(columns={\"Details\":\"Date\",\"Posting Date\":\"Description\",\"Description\":\"Amount\"})\n",
    "chase_df.reset_index(drop = True,inplace=True)\n",
    "chase_df['Amount'] = chase_df['Amount'].astype(float)\n",
    "chase_df['Amount'] = chase_df['Amount'].apply(lambda x: f\"+{x:.2f}\" if x > 0 else f\"{x:.2f}\")\n",
    "\n",
    "#Venmo\n",
    "venmo_df = venmo_df.iloc[:,[2,5,6,7,8]]\n",
    "venmo_df['Description'] = \"FROM: \"+ venmo_df[\"From\"] + \" TO: \"+ venmo_df[\"To\"] + \" NOTE: \" + venmo_df[\"Note\"]\n",
    "venmo_df['Date'] = pd.to_datetime(venmo_df['Datetime']).dt.strftime('%m/%d/%Y')\n",
    "venmo_df = venmo_df.iloc[:,[-1,-2,-3]]\n",
    "venmo_df.dropna(subset=['Description'],inplace=True)\n",
    "venmo_df.rename(columns = {\"Amount (total)\":\"Amount\"},inplace=True)\n",
    "venmo_df['Amount'] = venmo_df['Amount'].astype(str).str.replace(r'[\\$\\s,]', '', regex=True)\n",
    "\n",
    "#Wells Fargo\n",
    "wells_fargo_df = wells_fargo_df.iloc[:,[0,-1,1]]\n",
    "wells_fargo_df.rename(columns={0:\"Date\",4:\"Description\",1:\"Amount\"},inplace = True)\n",
    "wells_fargo_df[\"Amount\"] = wells_fargo_df[\"Amount\"].apply(\n",
    "    lambda x: f\"+{x:.2f}\" if x>0 else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9deb0756-3a74-4bec-b123-6db04a8ac994",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Concatinating the dataframes into one\n",
    "master_df = pd.concat([amex_df,chase_df,venmo_df,wells_fargo_df])\n",
    "master_df.sort_values([\"Date\"],inplace = True)\n",
    "master_df.reset_index(drop=True,inplace=True)\n",
    "master_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce8e9af-0f80-4439-a941-c01b86507d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing the Apple Pay prefix from payments\n",
    "master_df[\"Description\"] = master_df[\"Description\"].str.replace(\"AplPay\",\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec3fce72-b96c-40b0-84db-6c8f4a5f0160",
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.option_context('display.max_rows', None,\n",
    "                       'display.max_columns', None,\n",
    "                       'display.precision', 3,\n",
    "                       ):\n",
    "    print(master_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a08a7fd-9524-45fd-9ec0-b60ac4791a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df.insert(0,\"Expense Type\",\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "686aa1ab-78c3-46f2-a4d5-9fd4ab26f0f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df.insert(0,\"Expense\",\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a94e44c-ad33-4ed3-9777-c4eabaab24e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "expense_mapping = [\n",
    "    {\n",
    "        'patterns': [\"Trader Joe's\"],\n",
    "        'Expense': 'Groceries',\n",
    "        'Expense Type': 'Variable Need'\n",
    "    },\n",
    "    {\n",
    "        'patterns': [\"Sinclair Gas\"],\n",
    "        'Expense': 'Gas',\n",
    "        'Expense Type': 'Variable Need'\n",
    "    },\n",
    "    {\n",
    "        'patterns': [\"Thrive\"],\n",
    "        'Expense': 'Work Food',\n",
    "        'Expense Type': 'Variable Want'\n",
    "    },\n",
    "    {\n",
    "        'patterns': [\"Steam\"],\n",
    "        'Expense': 'Gaming',\n",
    "        'Expense Type': 'Variable Want'\n",
    "    },\n",
    "    {\n",
    "        'patterns': [\"Lemonade Insurance\"],\n",
    "        'Expense': 'Apartment',\n",
    "        'Expense Type': 'Fixed Need'\n",
    "    },\n",
    "    {\n",
    "        'patterns': [\"Uber Eats\"],\n",
    "        'Expense': 'Eating Out',\n",
    "        'Expense Type': 'Variable Want'\n",
    "    },\n",
    "    {\n",
    "        'patterns': [\"Nayax\"],\n",
    "        'Expense': 'Travel',\n",
    "        'Expense Type': 'Variable Need'\n",
    "    },\n",
    "    {\n",
    "        'patterns':['Klt floral'],\n",
    "        'Expense': 'Gifts',\n",
    "        'Expense Type': 'Variable Want'\n",
    "    },\n",
    "    {\n",
    "        'patterns':['Spectrum'],\n",
    "        'Expense': 'Internet',\n",
    "        'Expense Type': 'Fixed Need'\n",
    "    },\n",
    "    {\n",
    "        'patterns':['Cost Plus Drugs'],\n",
    "        'Expense': 'Medical',\n",
    "        'Expense Type': 'Variable Need'\n",
    "    },\n",
    "    {\n",
    "        'patterns':['Geico'],\n",
    "        'Expense': 'Car',\n",
    "        'Expense Type': 'Fixed Need'\n",
    "    }\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa5225c-19e4-4a33-9c81-5a675a66cd57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the mappings\n",
    "for mapping in expense_mapping:\n",
    "    # Create a regex pattern by joining the list of patterns with '|'\n",
    "    pattern = '|'.join(mapping['patterns'])\n",
    "    # Create a mask for rows where Description matches the pattern\n",
    "    mask = master_df['Description'].str.contains(pattern, case=False, na=False)\n",
    "    # Update 'Expense' and 'Expense Type' columns where the mask is True\n",
    "    master_df.loc[mask, 'Expense'] = mapping['Expense']\n",
    "    master_df.loc[mask, 'Expense Type'] = mapping['Expense Type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abca6f48-8fec-4796-a4f1-9a36ee6c8f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df['Description']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a44d0b3b-7638-4f55-bfc6-d398f31429d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df.to_clipboard(index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d790cda1-deb2-4956-bf8e-fe5e7f1b33ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(master_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (finances)",
   "language": "python",
   "name": "finances"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
