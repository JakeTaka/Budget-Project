{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "35786873-b9ce-45e9-abd2-ebfa22c7cbf6",
   "metadata": {},
   "source": [
    "## Monthly Budget Notebook\n",
    "#### Hi, thanks for taking a look at my budgeting notebook. This process used to be a lot simpler when I used a service called Empower and their \"Personal Dashboard\" for transaction aggregation. Then I started to notice some discrepancies and began to trust them less. After that, for some reason, their connectivity to Venmo went down the drain and as someone who uses Venmo a not insubstantial amount, it was leaving me with an incomplete picture of my monthly finances. I submitted support tickets but to no avail. \n",
    "\n",
    "#### So I figured this would be a useful project and at least then if I noticed things going wrong it'd be on _me_ and I'd be able to fix them _myself_.\n",
    "\n",
    "##### _NB: If you want to use this for your own budgeting purposes, feel free!_\n",
    "\n",
    "##### _Obvioulsy be careful and do so **at your own risk**. This is only set up right now for my own financial institutions that I use and has specific categorizations that I find helpful. The basic set-up for this notebook to work well is to have the notebook sitting in a directory (I have a structure that looks like this_\n",
    "##### _`~/home/jake/Budget/2025/2025-09`_\n",
    "##### _) and then have a sub directory called `Statements` which itself has a directory for each financial instituion that you have gathered statements from(`AmEx`,`Chase`,etc.)._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3793ad6-f1d1-4eb2-b1bf-5cdee13a7d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2393eac5-4874-47b5-bbf4-19c4cbc95398",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Aggregating a given month's statements into DataFrames\n",
    "amex_paths = glob.glob(\"Statements/Demo/AmEx/*.csv\")\n",
    "amex_df = pd.concat([pd.read_csv(file) for file in amex_paths])\n",
    "\n",
    "\n",
    "chase_path = glob.glob(\"Statements/Demo/Chase/*.csv\")\n",
    "chase_df = pd.read_csv(chase_path[0])\n",
    "\n",
    "venmo_path = glob.glob(\"Statements/Demo/Venmo/*.csv\")\n",
    "venmo_df = pd.read_csv(venmo_path[0])\n",
    "\n",
    "wells_fargo_path = glob.glob(\"Statements/Demo/Wells Fargo/*.csv\")\n",
    "wells_fargo_df = pd.read_csv(wells_fargo_path[0], header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11c4549e-501b-46a9-9c20-fe32d79cbd6b",
   "metadata": {},
   "source": [
    "### These next few cells can be safely turned off after actual use. I'm preserving them here to help show the process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba29597-43e1-49e2-a71b-1bd779ed7b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting a quick look at the df columns pt.1\n",
    "print(f\"AmEx Columns {amex_df.columns}\")\n",
    "print(f\"Chase Columns{chase_df.columns}\")\n",
    "print(f\"Venmo Columns{venmo_df.columns}\")\n",
    "print(f\"Wells Fargo Columns{wells_fargo_df.columns}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b1337d6-f95e-4fff-9763-220fad3b170e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting a quick look at the df columns pt.2\n",
    "print(amex_df.head())\n",
    "print(chase_df.head())\n",
    "print(venmo_df.head())\n",
    "print(wells_fargo_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f058f5f5-096d-44fe-8d9e-612af59c9941",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reordering the columns and dropping the ones I don't want before concatinating all of the dfs together\n",
    "\n",
    "#AmEx's csv is perfect. Exactly what I need and nothing more\n",
    "\n",
    "#Chase\n",
    "chase_df = chase_df.iloc[:,[1,2,3]]\n",
    "chase_df = chase_df.rename(columns={\"Posting Date\":\"Date\"})\n",
    "chase_df.reset_index(drop = True,inplace=True)\n",
    "\n",
    "#Venmo\n",
    "venmo_df = venmo_df.iloc[:,[1,4,5,6,7]]\n",
    "venmo_df['Description'] = \"FROM: \"+ venmo_df[\"From\"] + \" TO: \"+ venmo_df[\"To\"] + \" NOTE: \" + venmo_df[\"Note\"]\n",
    "venmo_df['Date'] = pd.to_datetime(venmo_df['Datetime']).dt.strftime('%m/%d/%Y')\n",
    "venmo_df = venmo_df.iloc[:,[-1,-2,-3]]\n",
    "venmo_df.dropna(subset=['Description'],inplace=True)\n",
    "venmo_df.rename(columns = {\"Amount (total)\":\"Amount\"},inplace=True)\n",
    "\n",
    "#Wells Fargo\n",
    "wells_fargo_df = wells_fargo_df.iloc[:,[0,-1,1]]\n",
    "wells_fargo_df.rename(columns={0:\"Date\",4:\"Description\",1:\"Amount\"},inplace = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (finances)",
   "language": "python",
   "name": "finances"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
